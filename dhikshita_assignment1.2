Script started on 2024-03-13 16:51:57+05:30 [TERM="xterm-256color" TTY="/dev/pts/0" COLUMNS="64" LINES="32"]
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ git clone [7mgit@github.com:Dhikshit[27m[7ma[27m[7m-macherla/mle-training.git[27m[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[Cgit@github.com:Dhikshita-macherla/mle-training.git
[?2004lCloning into 'mle-training'...
git@github.com: Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [7mgit@github.com:Dhikshita-macherla[27m[7m/[27m[7mmle-training.git[27m[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ git@github.com:Dhikshita-macherla/mle-training.git
[?2004lbash: git@github.com:Dhikshita-macherla/mle-training.git: No such file or directory
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ git clone [7mgit@github.com:Dhikshit[27m[7ma[27m[7m-macherla/mle-training.git[27m[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[Cgit@github.com:Dhikshita-macherla/mle-training.git
[?2004lCloning into 'mle-training'...
git@github.com: Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [7mssh-keygen -t ed25519 -C "your_em[27m[7ma[27m[7mil@example.com"[27m[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ ssh-keygen -t ed25519 -C "your_email@example.com"[1P.com"[1P.com"[1P.com"[1P.com"[1P.com"[1P.com"[1P.com"t.com"i.com"g.com"e.com"r.com"a.com"n.com"a.com"l.com"y.com"t.com"i.com"c.com"s.com"[1P@tigeranalytics.com"[C[C[1P@tigeranalytics.com"[C[1P@tigeranalytics.com"[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C@t[1Pigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C@ti[1Pgeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C@tig[1Peranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C@tige[1Pranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C@tiger[1Panalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C@tigera[1Pnalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C@tigeran[1Palytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cd@tigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ch@tigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ci@tigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ck@tigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs@tigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ch@tigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ci@tigeranalytics.com"t@tigeranalytics.com"[Ca@tigeranalytics.com"[C[C.@tigeranalytics.com"[C[C[Cm@tigeranalytics.com"[C[C[C[Ca@tigeranalytics.com"[C[C[C[C[Cc@tigeranalytics.com"[C[C[C[C[C[Ch@tigeranalytics.com"[C[C[C[C[C[C[Ce@tigeranalytics.com"[C[C[C[C[C[C[C[Cr@tigeranalytics.com"[C[C[C[C[C[C[C[C[C
[?2004lGenerating public/private ed25519 key pair.
Enter file in which to save the key (/home/dhikshita/.ssh/id_ed25519): 
Created directory '/home/dhikshita/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/dhikshita/.ssh/id_ed25519
Your public key has been saved in /home/dhikshita/.ssh/id_ed25519.pub
The key fingerprint is:
SHA256:pCKcs6LckveJNz4bk6wKRUnoqjkrT3umMappjBrMKHQ dhikshita.macher@tigeranalytics.com
The key's randomart image is:
+--[ED25519 256]--+
| ..              |
|.. .             |
|. o     .        |
| + .   o         |
|..*E. . S        |
|*..+...          |
|X+*  =           |
|@@.==++          |
|%*BB+=+          |
+----[SHA256]-----+
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [7meval "$(ssh-agent -s)"[27meval "$(ssh-agent -s)"
[?2004lAgent pid 23247
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [7mssh-add ~/.ssh/id_ed25519[27mssh-add ~/.ssh/id_ed25519
[?2004lEnter passphrase for /home/dhikshita/.ssh/id_ed25519: 
Identity added: /home/dhikshita/.ssh/id_ed25519 (dhikshita.macher@tigeranalytics.com)
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [7mcat ~/.ssh/id_ed25519.pub[27mcat ~/.ssh/id_ed25519.pub
[?2004lssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIM6F5S6dcuSbi/cnzZuFn8W/Ta8FyEHNq/2RrR/+sHTI dhikshita.macher@tigeranalytics.com
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ cat ~/.ssh/id_ed25519.pubssh-add ~/.ssh/id_ed25519[3Peval "$(ssh-agent -s)"ssh-keygen -t ed25519 -C "dhikshita.macher@tigeranalytics.com"[A(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ git clone git@github.com:Dhikshita[2P-macherla/mle-training.git
[?2004lCloning into 'mle-training'...
The authenticity of host 'github.com (20.207.73.82)' can't be established.
ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added 'github.com' (ED25519) to the list of known hosts.
remote: Enumerating objects: 3, done.[K
remote: Counting objects:  33% (1/3)[Kremote: Counting objects:  66% (2/3)[Kremote: Counting objects: 100% (3/3)[Kremote: Counting objects: 100% (3/3), done.[K
remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0[K
Receiving objects:  33% (1/3)Receiving objects:  66% (2/3)Receiving objects: 100% (3/3)Receiving objects: 100% (3/3), done.
[?2004h(base) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ cd mle-training
[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls
[?2004lREADME.md
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7mgit log --oneline --[27m[7md[27m[7mecorate[27m[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git log --oneline --decorate
[?2004l[?1h=[33mbdb5b20[m[33m ([m[1;36mHEAD[m[33m -> [m[1;32mmain[m[33m, [m[1;31morigin/main[m[33m, [m[1;31morigin/HEAD[m[33m)[m Initial commit[m
[K[?1l>[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7mgit checkout -b iss5[27m[7m3[27m[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git checkout -b iss53[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K[K[K[7menh/[27m[7m<[27m[7missue-id>/<short-msg>[27m[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cenh/<issue-id>/<short-msg>[1P>[1P>[1P>[1P>[1P>[1P>[1P>[1P>[1P>i>s>s>u>e>1>.>2>[1P>/<issue1.2>[C[C[C[C[C[C[C[C[1P>/<issue1.2>[C[C[C[C[C[C[C[1P>/<issue1.2>[C[C[C[C[C[C[1P>/<issue1.2>[C[C[C[C[C[1P>/<issue1.2>[C[C[C[C[1P>/<issue1.2>[C[C[C[1P>/<issue1.2>[C[C[1P>/<issue1.2>[C1>/<issue1.2>[C[C[1P>/<issue1.2>[C[1P>/<issue1.2>[1P/<issue1.2>1/<issue1.2>[C[C[1Pissue1.2>[C[C[C[C[C[C[C[C[C[C[C[K[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004lSwitched to a new branch 'enh/1/issue1.2'
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7mgit branch --all[27mgit branch --all
[?2004l[?1h=* [32menh/1/issue1.2[m[m
  main[m[m
  [31mremotes/origin/HEAD[m -> origin/main[m
  [31mremotes/origin/main[m[m
[K[?1l>[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7mgit push --set-upstr[27m[7me[27m[7mam origin corrected-branch-name[27m[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git push --set-upstream origin corrected-branch-name[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[7m enh/1/issue1.2[27m[C[C[C[C[C[C[C[C[C[C[C enh/1/issue1.2[1Penh/1/issue1.2[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004lTotal 0 (delta 0), reused 0 (delta 0), pack-reused 0
remote: 
remote: Create a pull request for 'enh/1/issue1.2' on GitHub by visiting:[K
remote:      https://github.com/Dhikshita-macherla/mle-training/pull/new/enh/1/issue1.2[K
remote: 
To github.com:Dhikshita-macherla/mle-training.git
 * [new branch]      enh/1/issue1.2 -> enh/1/issue1.2
branch 'enh/1/issue1.2' set up to track 'origin/enh/1/issue1.2'.
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano Re[KA[KEADME.md
[?2004l[?2004h[?1049h[22;0;0t[1;32r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[30;26H(B[0;7m[ Reading... ](B[m[30;25H(B[0;7m[ Read 1 line ](B[m[H(B[0;7m  GNU nano 6.2                README.md                         [1;63H(B[m[31d(B[0;7m^G(B[m Help     (B[0;7m^O(B[m Write Out(B[0;7m^W(B[m Where Is (B[0;7m^K(B[m Cut[49G(B[0;7m^T(B[m Execute[32d(B[0;7m^X(B[m Exit     (B[0;7m^R(B[m Read File(B[0;7m^\(B[m Replace  (B[0;7m^U(B[m Paste    (B[0;7m^J(B[m Justify[2d(B[0;1m[33m# mle-training[39m(B[m[?12l[?25h[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[C[?25l[?12l[?25h[3d[?25l[30d[J[32d[?12l[?25h[32;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano README.mdgit push --set-upstream origin enh/1/issue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[4Pbranch --all
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccheckout -b enh/1/issue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Clog --oneline --d[2Pecorate[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Ccheckout -b enh/1/issue1.2[C[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C enh/1/[1Pissue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C enh/1/i[1Pssue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[Cenh/1/is[C[1Pue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[C[C

[?2004lAlready on 'enh/1/issue1.2'
Your branch is up to date with 'origin/enh/1/issue1.2'.
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git checkout enh/1/issue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [6Pnano README.md
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004l[?2004h[?1049h[22;0;0t[1;32r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[30;26H(B[0;7m[ Reading... ](B[m[30;25H(B[0;7m[ Read 1 line ](B[m[H(B[0;7m  GNU nano 6.2                README.md                         [1;63H(B[m[31d(B[0;7m^G(B[m Help     (B[0;7m^O(B[m Write Out(B[0;7m^W(B[m Where Is (B[0;7m^K(B[m Cut[49G(B[0;7m^T(B[m Execute[32d(B[0;7m^X(B[m Exit     (B[0;7m^R(B[m Read File(B[0;7m^\(B[m Replace  (B[0;7m^U(B[m Paste    (B[0;7m^J(B[m Justify[2d(B[0;1m[33m# mle-training[39m(B[m[?12l[?25h[?25l[?12l[?25h[2;15H[?25l[1;41H(B[0;7m*[63G(B[m[3d[?12l[?25h[?25l[30d[K[3d(B[0;1m[33m# Median housing value prediction[5d[39m(B[mThe housing data can be downloaded from https://raw.githubuserc(B[0;7m>[7;1H(B[mThe following techniques have been used:[9d(B[0;1m[35m - [39m(B[mLinear regression[10d(B[0;1m[35m - [39m(B[mDecision Tree[11d(B[0;1m[35m - [39m(B[mRandom Forest[13d(B[0;1m[33m## Steps performed[14d[35m - [39m(B[mWe prepare and clean the data. We check and impute for missi(B[0;7m>[15;1H(B[0;1m[35m - [39m(B[mFeatures are generated and the variables are checked for cor(B[0;7m>[16;1H(B[0;1m[35m - [39m(B[mMultiple sampling techinuqies are evaluated. The data set is(B[0;7m>[17;1H(B[0;1m[35m - [39m(B[mAll the above said modelling techniques are tried and evalua(B[0;7m>[19;1H(B[0;1m[33m## To excute the script[20d[39m(B[mpython [36m< scriptname.py >[39m(B[m[?12l[?25h[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[17;25H[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[13;19H[?25l[?12l[?25h[A[?25l[?12l[?25h[11;17H[?25l[?12l[?25h[A[?25l[?12l[?25h[Asion[?25l[?12l[?25h[A[?25l[?12l[?25h[7;25H[?25l[?12l[?25h[A[?25l[?12l[?25h[5;25H[?25l[?12l[?25h[A[?25l[?12l[?25h[3;25H[?25l[?12l[?25h[2;15H[?25l[?12l[?25h[?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h[K[?25l[2;30r[30;1H
[1;32r[2;1H[?12l[?25h[?25l[?12l[?25h[3d[?25l[?12l[?25h[4d[?25l[?12l[?25h[5d[?25l[?12l[?25h[6d[?25l[?12l[?25h[7d[?25l[?12l[?25h[8d[?25l[?12l[?25h[9d[?25l[?12l[?25h[10d[?25l[?12l[?25h[11d[?25l[?12l[?25h[12d[?25l[?12l[?25h[13d[?25l[?12l[?25h[14d[?25l[?12l[?25h[15d[?25l[?12l[?25h[16d[?25l[?12l[?25h[17d[?25l[?12l[?25h[18d[?25l[?12l[?25h[19d[?25l[?12l[?25h[20d[?25l[31;13H    (B[0;7mM-D(B[m DOS Format  (B[0;7mM-A(B[m Append[49G(B[0;7mM-B(B[m Backup File[32;2H(B[0;7mC(B[m Cancel       (B[0;7mM-M(B[m Mac Format  (B[0;7mM-P(B[m Prepend     (B[0;7m^T(B[m Browse[K[30d(B[0;7mFile Name to Write: README.md                                   [30;30H(B[m[?12l[?25h[?25l[25G[1K (B[0;7m[ Writing... ](B[m[K[1;41H(B[0;7m [63G(B[m[30;24H(B[0;7m[ Wrote 18 lines ](B[m[31;13H(B[0;7m^O(B[m Write Out(B[0;7m^W(B[m Where Is (B[0;7m^K(B[m Cut[49G(B[0;7m^T(B[m Execute[K[32;2H(B[0;7mX(B[m Exit     (B[0;7m^R(B[m Read File(B[0;7m^\(B[m Replace  (B[0;7m^U(B[m Paste    (B[0;7m^J(B[m Justify[?12l[?25h[20d[?25l[30d[J[32d[?12l[?25h[32;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano[K[K[K[Kgit add README.md
[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git status
[?2004lOn branch enh/1/issue1.2
Your branch is up to date with 'origin/enh/1/issue1.2'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	[32mmodified:   README.md[m

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	[31mnonstandardcode.py:Zone.Identifier[m

[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git commiy [K[Kt -m "Fi[K[KNew B rranch [1P[C[C[C[C[C[C C o m m i t " 
[?2004l[enh/1/issue1.2 7195ba7] New Branch Commit
 1 file changed, 18 insertions(+), 1 deletion(-)
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git commit -m "New Branch Commit" [A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[10Pstatus
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004lOn branch enh/1/issue1.2
Your branch is ahead of 'origin/enh/1/issue1.2' by 1 commit.
  (use "git push" to publish your local commits)

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	[31mnonstandardcode.py:Zone.Identifier[m

nothing added to commit but untracked files present (use "git add" to track)
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls
[?2004lREADME.md  nonstandardcode.py:Zone.Identifier
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls
[?2004lREADME.md
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ lsgit status
[?2004lOn branch enh/1/issue1.2
Your branch is ahead of 'origin/enh/1/issue1.2' by 1 commit.
  (use "git push" to publish your local commits)

nothing to commit, working tree clean
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git push -f origin [7me[27m[7mn[27m[7mh/1/issue1.2[27m[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cenh/1/issue1.2
[?2004lEnumerating objects: 5, done.
Counting objects:  20% (1/5)Counting objects:  40% (2/5)Counting objects:  60% (3/5)Counting objects:  80% (4/5)Counting objects: 100% (5/5)Counting objects: 100% (5/5), done.
Delta compression using up to 12 threads
Compressing objects:  50% (1/2)Compressing objects: 100% (2/2)Compressing objects: 100% (2/2), done.
Writing objects:  33% (1/3)Writing objects:  66% (2/3)Writing objects: 100% (3/3)Writing objects: 100% (3/3), 675 bytes | 337.00 KiB/s, done.
Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
To github.com:Dhikshita-macherla/mle-training.git
   bdb5b20..7195ba7  enh/1/issue1.2 -> enh/1/issue1.2
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano non[K(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano non[K(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano non[K(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano non [K[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano non[K[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano non[K[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano nonstandardcode.py
[?2004l[?2004h[?1049h[22;0;0t[1;32r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[30;18H(B[0;7m[ New File ](B[m[H(B[0;7m  GNU nano 6.2   nonstandardcode.py            [1;46H(B[m[31d(B[0;7m^G(B[m Help    (B[0;7m^O(B[m Write Ou(B[0;7m^W(B[m Where Is(B[0;7m^K(B[m Cut[32d(B[0;7m^X(B[m Exit    (B[0;7m^R(B[m Read Fil(B[0;7m^\(B[m Replace (B[0;7m^U(B[m Paste[2d[?12l[?25h[?25l[30d[K[1;37H(B[0;7m*[46G(B[m[2dX_test_num = X_test.drop((B[0;1m[32m'ocean_proximity'[39m(B[m, ax(B[0;7m>[3;1H(B[mX_test_prepared = imputer.transform(X_test_num)[4;1HX_test_prepared = pd.DataFrame(X_test_prepared(B[0;7m>[5;27H(B[mindex=X_test.index)[6dX_test_prepared[(B[0;1m[32m"rooms_per_household"[39m(B[m] = X_tes(B[0;7m>[7;1H(B[mX_test_prepared[(B[0;1m[32m"bedrooms_per_room"[39m(B[m] = X_test_(B[0;7m>[8;1H(B[mX_test_prepared[(B[0;1m[32m"population_per_household"[39m(B[m]=X_(B[0;7m>[10;1H(B[mX_test_cat = X_test[[(B[0;1m[32m'ocean_proximity'[39m(B[m]][11dX_test_prepared = X_test_prepared.join(pd.get_(B[0;7m>[14;1H(B[mfinal_predictions = final_model.predict(X_test(B[0;7m>[15;1H(B[mfinal_mse = mean_squared_error(y_test, final_p(B[0;7m>[16;1H(B[mfinal_rmse = np.sqrt(final_mse)[?12l[?25h[32;1H[?1049l[23;0;0t[?1l>[?1049h[22;0;0t[1;33r[?12l[?25h[39;49m]104(B[m[4l[?7h[H[2J[?2004h[?1h=[?1h=(B[0;7m  GNU nano 6.2                                              nonstandardcode.py *                                                     [1;132H(B[m[2dX_test_num = X_test.drop((B[0;1m[32m'ocean_proximity'[39m(B[m, axis=1)[3dX_test_prepared = imputer.transform(X_test_num)[4dX_test_prepared = pd.DataFrame(X_test_prepared, columns=X_test_num.columns,[5;27Hindex=X_test.index)[6dX_test_prepared[(B[0;1m[32m"rooms_per_household"[39m(B[m] = X_test_prepared[(B[0;1m[32m"total_rooms"[39m(B[m]/X_test_prepared[(B[0;1m[32m"households"[39m(B[m][7dX_test_prepared[(B[0;1m[32m"bedrooms_per_room"[39m(B[m] = X_test_prepared[(B[0;1m[32m"total_bedrooms"[39m(B[m]/X_test_prepared[(B[0;1m[32m"total_rooms"[39m(B[m][8dX_test_prepared[(B[0;1m[32m"population_per_household"[39m(B[m]=X_test_prepared[(B[0;1m[32m"population"[39m(B[m]/X_test_prepared[(B[0;1m[32m"households"[39m(B[m][10dX_test_cat = X_test[[(B[0;1m[32m'ocean_proximity'[39m(B[m]][11dX_test_prepared = X_test_prepared.join(pd.get_dummies(X_test_cat, drop_first=(B[0;1m[35mTrue[39m(B[m))[14dfinal_predictions = final_model.predict(X_test_prepared)[15dfinal_mse = mean_squared_error(y_test, final_predictions)[16dfinal_rmse = np.sqrt(final_mse)[32d(B[0;7m^G(B[m Help[32;17H(B[0;7m^O(B[m Write Out    (B[0;7m^W(B[m Where Is     (B[0;7m^K(B[m Cut[32;65H(B[0;7m^T(B[m Execute[81G(B[0;7m^C(B[m Location     (B[0;7mM-U(B[m Undo[32;113H(B[0;7mM-A(B[m Set Mark[33d(B[0;7m^X(B[m Exit[33;17H(B[0;7m^R(B[m Read File    (B[0;7m^\(B[m Replace[49G(B[0;7m^U(B[m Paste[33;65H(B[0;7m^J(B[m Justify[81G(B[0;7m^/(B[m Go To Line   (B[0;7mM-E(B[m Redo[33;113H(B[0;7mM-6(B[m Copy[?25l[?12l[?25h[16;32H[?25l[?12l[?25h[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[11;32H[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[8;32H[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h[A[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hy_test = strat_test_set[(B[0;1m[32m"median_house_value"[39m(B[m].copy()[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1HX_test = strat_test_set.drop((B[0;1m[32m"median_house_value"[39m(B[m, axis=1)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hfinal_model = grid_search.best_estimator_[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hsorted(zip(feature_importances, housing_prepared.columns), reverse=(B[0;1m[35mTrue[39m(B[m)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hfeature_importances = grid_search.best_estimator_.feature_importances_[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;5Hprint(np.sqrt(-mean_score), params)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H(B[0;1m[36mfor[39m(B[m mean_score, params (B[0;1m[36min[39m(B[m zip(cvres[(B[0;1m[32m"mean_test_score"[39m(B[m], cvres[(B[0;1m[32m"params"[39m(B[m]):[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hcvres = grid_search.cv_results_[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hgrid_search.best_params_[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hgrid_search.fit(housing_prepared, housing_labels)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;28Hscoring=(B[0;1m[32m'neg_mean_squared_error'[39m(B[m, return_train_score=(B[0;1m[35mTrue[39m(B[m)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hgrid_search = GridSearchCV(forest_reg, param_grid, cv=5,[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H(B[0;1m[31m# train across 5 folds, that's a total of (12+6)*5=90 rounds of training(B[0m[42m [2;32H[49m(B[m[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hforest_reg = RandomForestRegressor(random_state=42)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;3H][?25l[?12l[?25h7[2;30r8M[1;33r[2;5H{(B[0;1m[32m'bootstrap'[39m(B[m: [(B[0;1m[35mFalse[39m(B[m], (B[0;1m[32m'n_estimators'[39m(B[m: [3, 10], (B[0;1m[32m'max_features'[39m(B[m: [2, 3, 4]},[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;4H(B[0;1m[31m # then try 6 (2×3) combinations with bootstrap set as False[2;32H[39m(B[m[?25l[?12l[?25h7[2;30r8M[1;33r[2;5H{(B[0;1m[32m'n_estimators'[39m(B[m: [3, 10, 30], (B[0;1m[32m'max_features'[39m(B[m: [2, 4, 6, 8]},[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;4H(B[0;1m[31m # try 12 (3×4) combinations of hyperparameters[2;32H[39m(B[m[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hparam_grid = [[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m GridSearchCV[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5Hprint(np.sqrt(-mean_score), params)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H(B[0;1m[36mfor[39m(B[m mean_score, params (B[0;1m[36min[39m(B[m zip(cvres[(B[0;1m[32m"mean_test_score"[39m(B[m], cvres[(B[0;1m[32m"params"[39m(B[m]):[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hcvres = rnd_search.cv_results_[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hrnd_search.fit(housing_prepared, housing_labels)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;33Hn_iter=10, cv=5, scoring=(B[0;1m[32m'neg_mean_squared_error'[39m(B[m, random_state=42)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hforest_reg = RandomForestRegressor(random_state=42)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5H}[?25l[?12l[?25h7[2;30r8M[1;33r[2;9H(B[0;1m[32m'max_features'[39m(B[m: randint(low=1, high=8),[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;9H(B[0;1m[32m'n_estimators'[39m(B[m: randint(low=1, high=200),[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hparam_distribs = {[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m scipy.stats (B[0;1m[36mimport[39m(B[m randint[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m RandomizedSearchCV[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.ensemble (B[0;1m[36mimport[39m(B[m RandomForestRegressor[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Htree_rmse[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Htree_rmse = np.sqrt(tree_mse)[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Htree_mse = mean_squared_error(housing_labels, housing_predictions)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing_predictions = tree_reg.predict(housing_prepared)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Htree_reg.fit(housing_prepared, housing_labels)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Htree_reg = DecisionTreeRegressor(random_state=42)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.tree (B[0;1m[36mimport[39m(B[m DecisionTreeRegressor[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hlin_mae[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hlin_mae = mean_absolute_error(housing_labels, housing_predictions)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.metrics (B[0;1m[36mimport[39m(B[m mean_absolute_error[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hlin_rmse[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hlin_rmse = np.sqrt(lin_mse)[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hlin_mse = mean_squared_error(housing_labels, housing_predictions)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing_predictions = lin_reg.predict(housing_prepared)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.metrics (B[0;1m[36mimport[39m(B[m mean_squared_error[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hlin_reg.fit(housing_prepared, housing_labels)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hlin_reg = LinearRegression()[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.linear_model (B[0;1m[36mimport[39m(B[m LinearRegression[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hhousing_prepared = housing_tr.join(pd.get_dummies(housing_cat, drop_first=(B[0;1m[35mTrue[39m(B[m))[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hhousing_cat = housing[[(B[0;1m[32m'ocean_proximity'[39m(B[m]][2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing_tr[(B[0;1m[32m"population_per_household"[39m(B[m]=housing_tr[(B[0;1m[32m"population"[39m(B[m]/housing_tr[(B[0;1m[32m"households"[39m(B[m][2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing_tr[(B[0;1m[32m"bedrooms_per_room"[39m(B[m] = housing_tr[(B[0;1m[32m"total_bedrooms"[39m(B[m]/housing_tr[(B[0;1m[32m"total_rooms"[39m(B[m][2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing_tr[(B[0;1m[32m"rooms_per_household"[39m(B[m] = housing_tr[(B[0;1m[32m"total_rooms"[39m(B[m]/housing_tr[(B[0;1m[32m"households"[39m(B[m][2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;27Hindex=housing.index)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing_tr = pd.DataFrame(X, columns=housing_num.columns,[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1HX = imputer.transform(housing_num)[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Himputer.fit(housing_num)[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hhousing_num = housing.drop((B[0;1m[32m'ocean_proximity'[39m(B[m, axis=1)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Himputer = SimpleImputer(strategy=(B[0;1m[32m"median"[39m(B[m)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.impute (B[0;1m[36mimport[39m(B[m SimpleImputer[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hhousing_labels = strat_train_set[(B[0;1m[32m"median_house_value"[39m(B[m].copy()[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing = strat_train_set.drop((B[0;1m[32m"median_house_value"[39m(B[m, axis=1)(B[0;1m[31m # drop labels for training set[2;32H[39m(B[m[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing[(B[0;1m[32m"population_per_household"[39m(B[m]=housing[(B[0;1m[32m"population"[39m(B[m]/housing[(B[0;1m[32m"households"[39m(B[m][2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing[(B[0;1m[32m"bedrooms_per_room"[39m(B[m] = housing[(B[0;1m[32m"total_bedrooms"[39m(B[m]/housing[(B[0;1m[32m"total_rooms"[39m(B[m][2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing[(B[0;1m[32m"rooms_per_household"[39m(B[m] = housing[(B[0;1m[32m"total_rooms"[39m(B[m]/housing[(B[0;1m[32m"households"[39m(B[m][2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hcorr_matrix[(B[0;1m[32m"median_house_value"[39m(B[m].sort_values(ascending=(B[0;1m[35mFalse[39m(B[m)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hcorr_matrix = housing.corr()[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hhousing.plot(kind=(B[0;1m[32m"scatter"[39m(B[m, x=(B[0;1m[32m"longitude"[39m(B[m, y=(B[0;1m[32m"latitude"[39m(B[m, alpha=0.1)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing.plot(kind=(B[0;1m[32m"scatter"[39m(B[m, x=(B[0;1m[32m"longitude"[39m(B[m, y=(B[0;1m[32m"latitude"[39m(B[m)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Hhousing = strat_train_set.copy()[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5Hset_.drop((B[0;1m[32m"income_cat"[39m(B[m, axis=1, inplace=(B[0;1m[35mTrue[39m(B[m)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H(B[0;1m[36mfor[39m(B[m set_ (B[0;1m[36min[39m(B[m (strat_train_set, strat_test_set):[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hcompare_props[(B[0;1m[32m"Strat. %error"[39m(B[m] = 100 * compare_props[(B[0;1m[32m"Stratified"[39m(B[m] / compare_props[(B[0;1m[32m"Overall"[39m(B[m] - 100[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hcompare_props[(B[0;1m[32m"Rand. %error"[39m(B[m] = 100 * compare_props[(B[0;1m[32m"Random"[39m(B[m] / compare_props[(B[0;1m[32m"Overall"[39m(B[m] - 100[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H}).sort_index()[?25l[?12l[?25h7[2;30r8M[1;33r[2;5H(B[0;1m[32m"Random"[39m(B[m: income_cat_proportions(test_set),[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;5H(B[0;1m[32m"Stratified"[39m(B[m: income_cat_proportions(strat_test_set),[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5H(B[0;1m[32m"Overall"[39m(B[m: income_cat_proportions(housing),[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hcompare_props = pd.DataFrame({[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Htrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5H(B[0;1m[36mreturn[39m(B[m data[(B[0;1m[32m"income_cat"[39m(B[m].value_counts() / len(data)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mdef[34m income_cat_proportions[39m(B[m(data):[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5Hstrat_test_set = housing.loc[test_index][2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;5Hstrat_train_set = housing.loc[train_index][2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfor[39m(B[m train_index, test_index (B[0;1m[36min[39m(B[m split.split(housing, housing[(B[0;1m[32m"income_cat"[39m(B[m]):[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m StratifiedShuffleSplit[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;32Hlabels=[1, 2, 3, 4, 5])[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;32Hbins=[0., 1.5, 3.0, 4.5, 6., np.inf],[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing[(B[0;1m[32m"income_cat"[39m(B[m] = pd.cut(housing[(B[0;1m[32m"median_income"[39m(B[m],[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1Htrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m train_test_split[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1Hhousing = load_housing_data[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5H(B[0;1m[36mreturn[39m(B[m pd.read_csv(csv_path)[?25l[?12l[?25h7[2;30r8M[1;33r[2;5Hcsv_path = os.path.join(housing_path, (B[0;1m[32m"housing.csv"[39m(B[m)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mdef[34m load_housing_data[39m(B[m(housing_path=HOUSING_PATH):[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mimport[39m(B[m pandas (B[0;1m[36mas[39m(B[m pd[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5Hhousing_tgz.close()[?25l[?12l[?25h7[2;31r8M[1;33r[2;5Hhousing_tgz.extractall(path=housing_path)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5Hhousing_tgz = tarfile.open(tgz_path)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;5Hurllib.request.urlretrieve(housing_url, tgz_path)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;5Htgz_path = os.path.join(housing_path, (B[0;1m[32m"housing.tgz"[39m(B[m)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;5Hos.makedirs(housing_path, exist_ok=(B[0;1m[35mTrue[39m(B[m)[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mdef[34m fetch_housing_data[39m(B[m(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):[2;32H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1HHOUSING_URL = DOWNLOAD_ROOT + (B[0;1m[32m"datasets/housing/housing.tgz"[2;32H[39m(B[m[?25l[?12l[?25h7[2;30r8M[1;33r[2;1HHOUSING_PATH = os.path.join((B[0;1m[32m"datasets"[39m(B[m, (B[0;1m[32m"housing"[39m(B[m)[2;32H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1HDOWNLOAD_ROOT = (B[0;1m[32m"https://raw.githubusercontent.com/ageron/handson-ml/master/"[2;32H[39m(B[m[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mfrom[39m(B[m six.moves (B[0;1m[36mimport[39m(B[m urllib[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mimport[39m(B[m tarfile[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mimport[39m(B[m os[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H(B[0;1m[36mimport[39m(B[m matplotlib.pyplot (B[0;1m[36mas[39m(B[m plt[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mimport[39m(B[m matplotlib (B[0;1m[36mas[39m(B[m mpl[?25l[?12l[?25h7[2;31r8M[1;33r[2;1H(B[0;1m[36mimport[39m(B[m pandas (B[0;1m[36mas[39m(B[m pd[?25l[?12l[?25h7[2;30r8M[1;33r[2;1H(B[0;1m[36mimport[39m(B[m numpy (B[0;1m[36mas[39m(B[m np[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[3dd[?25l[?12l[?25h[4;25H[?25l[?12l[?25h[5;32H[?25l[?12l[?25h[6;10H[?25l[?12l[?25h[7;15H[?25l[?12l[?25h[8;29H[?25l[?12l[?25h[9d[?25l[?12l[?25h[10d[?25l[?12l[?25h[11;32H[?25l[?12l[?25h[12d[?25l[?12l[?25h[13d[?25l[?12l[?25h[14d[?25l[?12l[?25h[15;32H[?25l[?12l[?25h[16d[?25l[?12l[?25h[17d[?25l[?12l[?25h[18d[?25l[?12l[?25h[19d[?25l[?12l[?25h[20d[?25l[?12l[?25h[21;24H[?25l[?12l[?25h[22d[?25l[?12l[?25h[23;20H[?25l[?12l[?25h[24d[?25l[?12l[?25h[25;32H[?25l[?12l[?25h[26d[?25l[?12l[?25h[27d[?25l[?12l[?25h[28d[?25l[?12l[?25h[29;28H[?25l[?12l[?25h[30d[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m train_test_split[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Htrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing[(B[0;1m[32m"income_cat"[39m(B[m] = pd.cut(housing[(B[0;1m[32m"median_income"[39m(B[m],[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;32Hbins=[0., 1.5, 3.0, 4.5, 6., np.inf],[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;32Hlabels=[1, 2, 3, 4, 5])[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m StratifiedShuffleSplit[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfor[39m(B[m train_index, test_index (B[0;1m[36min[39m(B[m split.split(housing, housing[(B[0;1m[32m"income_cat"[39m(B[m]):[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5Hstrat_train_set = housing.loc[train_index][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5Hstrat_test_set = housing.loc[test_index][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mdef[34m income_cat_proportions[39m(B[m(data):[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5H(B[0;1m[36mreturn[39m(B[m data[(B[0;1m[32m"income_cat"[39m(B[m].value_counts() / len(data)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Htrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hcompare_props = pd.DataFrame({[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5H(B[0;1m[32m"Overall"[39m(B[m: income_cat_proportions(housing),[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5H(B[0;1m[32m"Stratified"[39m(B[m: income_cat_proportions(strat_test_set),[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5H(B[0;1m[32m"Random"[39m(B[m: income_cat_proportions(test_set),[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H}).sort_index()[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hcompare_props[(B[0;1m[32m"Rand. %error"[39m(B[m] = 100 * compare_props[(B[0;1m[32m"Random"[39m(B[m] / compare_props[(B[0;1m[32m"Overall"[39m(B[m] - 100[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hcompare_props[(B[0;1m[32m"Strat. %error"[39m(B[m] = 100 * compare_props[(B[0;1m[32m"Stratified"[39m(B[m] / compare_props[(B[0;1m[32m"Overall"[39m(B[m] - 100[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfor[39m(B[m set_ (B[0;1m[36min[39m(B[m (strat_train_set, strat_test_set):[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5Hset_.drop((B[0;1m[32m"income_cat"[39m(B[m, axis=1, inplace=(B[0;1m[35mTrue[39m(B[m)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing = strat_train_set.copy()[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing.plot(kind=(B[0;1m[32m"scatter"[39m(B[m, x=(B[0;1m[32m"longitude"[39m(B[m, y=(B[0;1m[32m"latitude"[39m(B[m)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing.plot(kind=(B[0;1m[32m"scatter"[39m(B[m, x=(B[0;1m[32m"longitude"[39m(B[m, y=(B[0;1m[32m"latitude"[39m(B[m, alpha=0.1)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hcorr_matrix = housing.corr()[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hcorr_matrix[(B[0;1m[32m"median_house_value"[39m(B[m].sort_values(ascending=(B[0;1m[35mFalse[39m(B[m)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing[(B[0;1m[32m"rooms_per_household"[39m(B[m] = housing[(B[0;1m[32m"total_rooms"[39m(B[m]/housing[(B[0;1m[32m"households"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing[(B[0;1m[32m"bedrooms_per_room"[39m(B[m] = housing[(B[0;1m[32m"total_bedrooms"[39m(B[m]/housing[(B[0;1m[32m"total_rooms"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing[(B[0;1m[32m"population_per_household"[39m(B[m]=housing[(B[0;1m[32m"population"[39m(B[m]/housing[(B[0;1m[32m"households"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing = strat_train_set.drop((B[0;1m[32m"median_house_value"[39m(B[m, axis=1)(B[0;1m[31m # drop labels for training set[30;32H[39m(B[m[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_labels = strat_train_set[(B[0;1m[32m"median_house_value"[39m(B[m].copy()[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.impute (B[0;1m[36mimport[39m(B[m SimpleImputer[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Himputer = SimpleImputer(strategy=(B[0;1m[32m"median"[39m(B[m)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_num = housing.drop((B[0;1m[32m'ocean_proximity'[39m(B[m, axis=1)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Himputer.fit(housing_num)[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX = imputer.transform(housing_num)[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_tr = pd.DataFrame(X, columns=housing_num.columns,[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;27Hindex=housing.index)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_tr[(B[0;1m[32m"rooms_per_household"[39m(B[m] = housing_tr[(B[0;1m[32m"total_rooms"[39m(B[m]/housing_tr[(B[0;1m[32m"households"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_tr[(B[0;1m[32m"bedrooms_per_room"[39m(B[m] = housing_tr[(B[0;1m[32m"total_bedrooms"[39m(B[m]/housing_tr[(B[0;1m[32m"total_rooms"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_tr[(B[0;1m[32m"population_per_household"[39m(B[m]=housing_tr[(B[0;1m[32m"population"[39m(B[m]/housing_tr[(B[0;1m[32m"households"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_cat = housing[[(B[0;1m[32m'ocean_proximity'[39m(B[m]][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_prepared = housing_tr.join(pd.get_dummies(housing_cat, drop_first=(B[0;1m[35mTrue[39m(B[m))[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.linear_model (B[0;1m[36mimport[39m(B[m LinearRegression[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hlin_reg = LinearRegression()[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hlin_reg.fit(housing_prepared, housing_labels)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.metrics (B[0;1m[36mimport[39m(B[m mean_squared_error[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_predictions = lin_reg.predict(housing_prepared)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hlin_mse = mean_squared_error(housing_labels, housing_predictions)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hlin_rmse = np.sqrt(lin_mse)[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hlin_rmse[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.metrics (B[0;1m[36mimport[39m(B[m mean_absolute_error[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hlin_mae = mean_absolute_error(housing_labels, housing_predictions)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hlin_mae[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.tree (B[0;1m[36mimport[39m(B[m DecisionTreeRegressor[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Htree_reg = DecisionTreeRegressor(random_state=42)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Htree_reg.fit(housing_prepared, housing_labels)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hhousing_predictions = tree_reg.predict(housing_prepared)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Htree_mse = mean_squared_error(housing_labels, housing_predictions)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Htree_rmse = np.sqrt(tree_mse)[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Htree_rmse[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.ensemble (B[0;1m[36mimport[39m(B[m RandomForestRegressor[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m RandomizedSearchCV[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m scipy.stats (B[0;1m[36mimport[39m(B[m randint[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hparam_distribs = {[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;9H(B[0;1m[32m'n_estimators'[39m(B[m: randint(low=1, high=200),[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;9H(B[0;1m[32m'max_features'[39m(B[m: randint(low=1, high=8),[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5H}[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hforest_reg = RandomForestRegressor(random_state=42)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;33Hn_iter=10, cv=5, scoring=(B[0;1m[32m'neg_mean_squared_error'[39m(B[m, random_state=42)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hrnd_search.fit(housing_prepared, housing_labels)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hcvres = rnd_search.cv_results_[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfor[39m(B[m mean_score, params (B[0;1m[36min[39m(B[m zip(cvres[(B[0;1m[32m"mean_test_score"[39m(B[m], cvres[(B[0;1m[32m"params"[39m(B[m]):[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5Hprint(np.sqrt(-mean_score), params)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfrom[39m(B[m sklearn.model_selection (B[0;1m[36mimport[39m(B[m GridSearchCV[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hparam_grid = [[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;4H(B[0;1m[31m # try 12 (3×4) combinations of hyperparameters[30;32H[39m(B[m[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5H{(B[0;1m[32m'n_estimators'[39m(B[m: [3, 10, 30], (B[0;1m[32m'max_features'[39m(B[m: [2, 4, 6, 8]},[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;4H(B[0;1m[31m # then try 6 (2×3) combinations with bootstrap set as False[30;32H[39m(B[m[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5H{(B[0;1m[32m'bootstrap'[39m(B[m: [(B[0;1m[35mFalse[39m(B[m], (B[0;1m[32m'n_estimators'[39m(B[m: [3, 10], (B[0;1m[32m'max_features'[39m(B[m: [2, 3, 4]},[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;3H][?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hforest_reg = RandomForestRegressor(random_state=42)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[31m# train across 5 folds, that's a total of (12+6)*5=90 rounds of training(B[0m[42m [30;32H[49m(B[m[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hgrid_search = GridSearchCV(forest_reg, param_grid, cv=5,[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;28Hscoring=(B[0;1m[32m'neg_mean_squared_error'[39m(B[m, return_train_score=(B[0;1m[35mTrue[39m(B[m)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hgrid_search.fit(housing_prepared, housing_labels)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hgrid_search.best_params_[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hcvres = grid_search.cv_results_[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H(B[0;1m[36mfor[39m(B[m mean_score, params (B[0;1m[36min[39m(B[m zip(cvres[(B[0;1m[32m"mean_test_score"[39m(B[m], cvres[(B[0;1m[32m"params"[39m(B[m]):[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;5Hprint(np.sqrt(-mean_score), params)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hfeature_importances = grid_search.best_estimator_.feature_importances_[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hsorted(zip(feature_importances, housing_prepared.columns), reverse=(B[0;1m[35mTrue[39m(B[m)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hfinal_model = grid_search.best_estimator_[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test = strat_test_set.drop((B[0;1m[32m"median_house_value"[39m(B[m, axis=1)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hy_test = strat_test_set[(B[0;1m[32m"median_house_value"[39m(B[m].copy()[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_num = X_test.drop((B[0;1m[32m'ocean_proximity'[39m(B[m, axis=1)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_prepared = imputer.transform(X_test_num)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_prepared = pd.DataFrame(X_test_prepared, columns=X_test_num.columns,[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;27Hindex=X_test.index)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_prepared[(B[0;1m[32m"rooms_per_household"[39m(B[m] = X_test_prepared[(B[0;1m[32m"total_rooms"[39m(B[m]/X_test_prepared[(B[0;1m[32m"households"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_prepared[(B[0;1m[32m"bedrooms_per_room"[39m(B[m] = X_test_prepared[(B[0;1m[32m"total_bedrooms"[39m(B[m]/X_test_prepared[(B[0;1m[32m"total_rooms"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_prepared[(B[0;1m[32m"population_per_household"[39m(B[m]=X_test_prepared[(B[0;1m[32m"population"[39m(B[m]/X_test_prepared[(B[0;1m[32m"households"[39m(B[m][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_cat = X_test[[(B[0;1m[32m'ocean_proximity'[39m(B[m]][30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1HX_test_prepared = X_test_prepared.join(pd.get_dummies(X_test_cat, drop_first=(B[0;1m[35mTrue[39m(B[m))[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hfinal_predictions = final_model.predict(X_test_prepared)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hfinal_mse = mean_squared_error(y_test, final_predictions)[30;32H[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1Hfinal_rmse = np.sqrt(final_mse)[?25l[?12l[?25h7[2;31r8[31d
[1;33r[30;1H[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[32;17H[17X[32;34H(B[0;7mM-D(B[m DOS Format       [32;65H  (B[0;7mM-A(B[m Append[23X[32;100H(B[0;7mM-B(B[m Backup File[K[33;2H(B[0;7mC(B[m Cancel[17G[17X[33;34H(B[0;7mM-M(B[m Mac Format         [33;65H  (B[0;7mM-P(B[m Prepend[22X[33;100H(B[0;7m^T(B[m Browse[K[31d(B[0;7mFile Name to Write: nonstandardcode.py                                                                                               [31;39H(B[m[?12l[?25h[?25l[31;59H[1K (B[0;7m[ Writing... ](B[m[K[1;80H(B[0;7m [132G(B[m[31;58H(B[0;7m[ Wrote 181 lines ](B[m[32;17H(B[0;7m^O(B[m Write Out    (B[0;7m^W(B[m Where Is     (B[0;7m^K(B[m Cut[32;65H(B[0;7m^T(B[m Execute      (B[0;7m^C(B[m Location     (B[0;7mM-U(B[m Undo        (B[0;7mM-A(B[m Set Mark[33;2H(B[0;7mX(B[m Exit  [17G(B[0;7m^R(B[m Read File    (B[0;7m^\(B[m Replace      (B[0;7m^U(B[m Paste[33;65H(B[0;7m^J(B[m Justify      (B[0;7m^/(B[m Go To Line   (B[0;7mM-E(B[m Redo        (B[0;7mM-6(B[m Copy[?12l[?25h[30d[?25l[31d[J[33d[?12l[?25h[33;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano nonstandardcode.pygit push -f origin enh/1/issue1.2status[Kls[Kgit status
[?2004lOn branch enh/1/issue1.2
Your branch is up to date with 'origin/enh/1/issue1.2'.

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	[31mnonstandardcode.py[m

nothing added to commit but untracked files present (use "git add" to track)
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git statusnano nonstandardcode.pygit push -f origin enh/1/issue1.2status[Kls[Kgit statuscommit -m "New Branch Commit" status[Kadd README.md[K[K[K[K[K[K[K[K[K[7m nonstandardcode.py[27m nonstandardcode.py[1Pnonstandardcode.py
[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git add nonstandardcode.pystatus[Knano nonstandardcode.pygit push -f origin enh/1/issue1.2status[Kls[Kgit statuscommit -m "New Branch Commit" 
[?2004l[enh/1/issue1.2 fd3e9f8] New Branch Commit
 1 file changed, 181 insertions(+)
 create mode 100644 nonstandardcode.py
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git commit -m "New Branch Commit" [8Padd nonstandardcode.pystatus[Knano nonstandardcode.py[13Pgit status
[?2004lOn branch enh/1/issue1.2
Your branch is ahead of 'origin/enh/1/issue1.2' by 1 commit.
  (use "git push" to publish your local commits)

nothing to commit, working tree clean
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git statuscommit -m "New Branch Commit" [8Padd nonstandardcode.pystatus[Knano nonstandardcode.pygit push -f origin enh/1/issue1.2
[?2004lEnumerating objects: 4, done.
Counting objects:  25% (1/4)Counting objects:  50% (2/4)Counting objects:  75% (3/4)Counting objects: 100% (4/4)Counting objects: 100% (4/4), done.
Delta compression using up to 12 threads
Compressing objects:  33% (1/3)Compressing objects:  66% (2/3)Compressing objects: 100% (3/3)Compressing objects: 100% (3/3), done.
Writing objects:  33% (1/3)Writing objects:  66% (2/3)Writing objects: 100% (3/3)Writing objects: 100% (3/3), 2.27 KiB | 211.00 KiB/s, done.
Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
To github.com:Dhikshita-macherla/mle-training.git
   7195ba7..fd3e9f8  enh/1/issue1.2 -> enh/1/issue1.2
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [K(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [K(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [K(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano gitignore.gitignore [A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C
[?2004l[?2004h[?1049h[22;0;0t[1;32r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[30;24H(B[0;7m[ New File ](B[m[H(B[0;7m  GNU nano 6.2             .gitignore                      [1;58H(B[m[31d(B[0;7m^G(B[m Help[15G(B[0;7m^O(B[m Write Out  (B[0;7m^W(B[m Where Is   (B[0;7m^K(B[m Cut[32d(B[0;7m^X(B[m Exit[15G(B[0;7m^R(B[m Read File  (B[0;7m^\(B[m Replace    (B[0;7m^U(B[m Paste[2d[?12l[?25h[?25l[30d[K[1;39H(B[0;7m*[58G(B[m[2d[36m# ignore all logs[3d[39m(B[m*.log[?12l[?25h[?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25h [?25l[?12l[?25hp[?25l[?12l[?25hy[?25l[?12l[?25hc[?25l[?12l[?25h,[?25l[?12l[?25h [?25l[?12l[?25h[?25l[?12l[?25h [?25l[4d[?12l[?25h[?25l[?12l[?25h*[?25l[?12l[?25h.[?25l[?12l[?25hc[?25l[?12l[?25hd[?25l[?12l[?25h [?25l[?12l[?25hs[?25l[?12l[?25hv[?25l[31;15H(B[0;7mM-D(B[m DOS Format(B[0;7mM-A(B[m Append    (B[0;7mM-B(B[m Backup File[32;2H(B[0;7mC(B[m Cancel     (B[0;7mM-M(B[m Mac Format(B[0;7mM-P(B[m Prepend   (B[0;7m^T(B[m Browse[30d(B[0;7mFile Name to Write: .gitignore                             [30;31H(B[m[?12l[?25h[?25l[30;22H[1K (B[0;7m[ Writing... ](B[m[K[1;39H(B[0;7m [58G(B[m[30;22H(B[0;7m[ Wrote 3 lines ](B[m[31;15H(B[0;7m^O(B[m Write Out  (B[0;7m^W(B[m Where Is   (B[0;7m^K(B[m Cut[K[32;2H(B[0;7mX(B[m Exit       (B[0;7m^R(B[m Read File  (B[0;7m^\(B[m Replace    (B[0;7m^U(B[m Paste[K[?12l[?25h[4;6H[?25l[30d[J[32d[?12l[?25h[32;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ catnano .gitignore [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1P .gitignore
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1P .gitignore[1P .gitignore[1P .gitignorec .gitignorea .gitignoret .gitignore
[?2004l# ignore all logs
*.pyc
*.csv
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda create -- name mle [K_dev
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Retrieving notices: ...working... done
Channels:
 - defaults
Platform: linux-64
Collecting package metadata (repodata.json): \ | / - \ | / - \ | / - done
Solving environment: | done

## Package Plan ##

  environment location: /home/dhikshita/miniconda3/envs/mle_dev



Proceed ([y]/n)? y

Preparing transaction: - done
Verifying transaction: | done
Executing transaction: - done
#
# To activate this environment, use
#
#     $ conda activate mle_dev
#
# To deactivate an active environment, use
#
#     $ conda deactivate

[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda create --name mle_dev[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[1Pat .gitignore
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cnano .gitignore [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit push -f origin enh/1/issue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[5Pstatus
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccommit -m "New Branch Commit" [A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Cadd nonstand[8Pardcode.py[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Ccommit -m "New Branch Commit" [A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Cadd nonstand[8Pardcode.py[K[K[K[K[K[K[K[K[K[K[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K[K[K[K[K[K.gitign ore
[?2004l[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git add .gitignore[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda create --name mle_dev[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[1Pat .gitignore
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cnano .gitignore [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit push -f origin enh/1/issue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[5Pstatus
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccommit -m "New Branch Commit" 
[?2004l[enh/1/issue1.2 c220def] New Branch Commit
 1 file changed, 3 insertions(+)
 create mode 100644 .gitignore
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git commit -m "New Branch Commit" [A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Cadd .gitignore[K[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda create --name mle_dev[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[1Pat .gitignore
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cnano .gitignore [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1Pcat
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Conda create --name mle_dev[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git add .gitignore[K[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Ccommit -m "New Branch Commit" [A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit commit -m "New Branch Commit" [A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Cadd .gitignore[K[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda create --name mle_dev[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[1Pat .gitignore
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cnano .gitignore [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit push -f origin enh/1/issue1.2
[?2004lEnumerating objects: 4, done.
Counting objects:  25% (1/4)Counting objects:  50% (2/4)Counting objects:  75% (3/4)Counting objects: 100% (4/4)Counting objects: 100% (4/4), done.
Delta compression using up to 12 threads
Compressing objects:  50% (1/2)Compressing objects: 100% (2/2)Compressing objects: 100% (2/2), done.
Writing objects:  33% (1/3)Writing objects:  66% (2/3)Writing objects: 100% (3/3)Writing objects: 100% (3/3), 364 bytes | 364.00 KiB/s, done.
Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
To github.com:Dhikshita-macherla/mle-training.git
   fd3e9f8..c220def  enh/1/issue1.2 -> enh/1/issue1.2
[?2004h(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git push -f origin enh/1/issue1.2[A(base) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cconda activate  mle_dev
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda instal l python
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Channels:
 - defaults
Platform: linux-64
Collecting package metadata (repodata.json): - \ | / - \ | done
Solving environment: - done

## Package Plan ##

  environment location: /home/dhikshita/miniconda3/envs/mle_dev

  added / updated specs:
    - python


The following NEW packages will be INSTALLED:

  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main 
  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu 
  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_5 
  ca-certificates    pkgs/main/linux-64::ca-certificates-2023.12.12-h06a4308_0 
  expat              pkgs/main/linux-64::expat-2.5.0-h6a678d5_0 
  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 
  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_0 
  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 
  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 
  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 
  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 
  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 
  openssl            pkgs/main/linux-64::openssl-3.0.13-h7f8727e_0 
  pip                pkgs/main/linux-64::pip-23.3.1-py312h06a4308_0 
  python             pkgs/main/linux-64::python-3.12.2-h996f2a0_0 
  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 
  setuptools         pkgs/main/linux-64::setuptools-68.2.2-py312h06a4308_0 
  sqlite             pkgs/main/linux-64::sqlite-3.41.2-h5eee18b_0 
  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0 
  tzdata             pkgs/main/noarch::tzdata-2024a-h04d1e81_0 
  wheel              pkgs/main/linux-64::wheel-0.41.2-py312h06a4308_0 
  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_0 
  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_0 


Proceed ([y]/n)? y


Downloading and Extracting Packages:

Preparing transaction: | / - done
Verifying transaction: | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / done
Executing transaction: \ | / - \ | / done
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda env ex port >environment.yml
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 12, column 2
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ cd ..
[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ nano .condaarc
[?2004l[?2004h[?1049h[22;0;0t[1;32r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[30;24H(B[0;7m[ New File ](B[m[H(B[0;7m  GNU nano 6.2             .condaarc                       [1;58H(B[m[31d(B[0;7m^G(B[m Help[15G(B[0;7m^O(B[m Write Out  (B[0;7m^W(B[m Where Is   (B[0;7m^K(B[m Cut[32d(B[0;7m^X(B[m Exit[15G(B[0;7m^R(B[m Read File  (B[0;7m^\(B[m Replace    (B[0;7m^U(B[m Paste[2d[?12l[?25h[?25l[30d[J[32d[?12l[?25h[32;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ nano .condaarc[1Prc
[?2004l[?2004h[?1049h[22;0;0t[1;32r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[30;23H(B[0;7m[ Reading... ](B[m[30;22H(B[0;7m[ Read 46 lines ](B[m[H(B[0;7m  GNU nano 6.2              .condarc                       [1;58H(B[m[31d(B[0;7m^G(B[m Help[15G(B[0;7m^O(B[m Write Out  (B[0;7m^W(B[m Where Is   (B[0;7m^K(B[m Cut[32d(B[0;7m^X(B[m Exit[15G(B[0;7m^R(B[m Read File  (B[0;7m^\(B[m Replace    (B[0;7m^U(B[m Paste[2dnotify_outdated_conda: false[3dauto_stack: 1[4dchangeps1: False[5dadd_pip_as_python_dependency: True[6duse_pip: False[7dproxy_servers:[8;5Hhttp: [94mhttp://user:pass@corp.com:8080[9;5H[39m(B[mhttps: [94mhttps://user:pass@corp.com:8080[10d[39m(B[mchannel_priority: strict[11dcreate_default_packages:[12;3H- python[13;3H-ipython[14;3H-scipy=0.15.0[15dtrack_features:[16;3H- mkl[17dupdate_dependencies: True[18dssl_verify: True[19doffline: False[20dallow_softlinks: True[21dchannel_alias: [94mhttps://mdconda.com[22d[39m(B[mssl_verify: corp.crt[23dreport_errors: true[24dauto_update_conda: False[25dalways_yes: True[26dshow_channel_urls: True[27dcustom_channels:[28;5Hconda-forge: [94mhttps://my-mirror.com/conda-forge[29d[39m(B[mchannels:[2d[?12l[?25h[?25l[30d[J[32d[?12l[?25h[32;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ nano .condarc
[?2004l[?2004h[?1049h[22;0;0t[1;32r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[30;23H(B[0;7m[ Reading... ](B[m[30;22H(B[0;7m[ Read 46 lines ](B[m[H(B[0;7m  GNU nano 6.2              .condarc                       [1;58H(B[m[31d(B[0;7m^G(B[m Help[15G(B[0;7m^O(B[m Write Out  (B[0;7m^W(B[m Where Is   (B[0;7m^K(B[m Cut[32d(B[0;7m^X(B[m Exit[15G(B[0;7m^R(B[m Read File  (B[0;7m^\(B[m Replace    (B[0;7m^U(B[m Paste[2dnotify_outdated_conda: false[3dauto_stack: 1[4dchangeps1: False[5dadd_pip_as_python_dependency: True[6duse_pip: False[7dproxy_servers:[8;5Hhttp: [94mhttp://user:pass@corp.com:8080[9;5H[39m(B[mhttps: [94mhttps://user:pass@corp.com:8080[10d[39m(B[mchannel_priority: strict[11dcreate_default_packages:[12;3H- python[13;3H-ipython[14;3H-scipy=0.15.0[15dtrack_features:[16;3H- mkl[17dupdate_dependencies: True[18dssl_verify: True[19doffline: False[20dallow_softlinks: True[21dchannel_alias: [94mhttps://mdconda.com[22d[39m(B[mssl_verify: corp.crt[23dreport_errors: true[24dauto_update_conda: False[25dalways_yes: True[26dshow_channel_urls: True[27dcustom_channels:[28;5Hconda-forge: [94mhttps://my-mirror.com/conda-forge[29d[39m(B[mchannels:[2d[?12l[?25h[?25l[?12l[?25h[3d[?25l[?12l[?25h[A[?25l[1;38H(B[0;7m*[58G(B[m[2;30r[30;1H
[1;32r[29;3H- <anaconda_dot_org_username>[K[2d[?12l[?25h[?25l[2;30r[30;1H
[1;32r[29;3H- [94mhttp://some.custom/channel[2d[39m(B[m[?12l[?25h[?25l[?12l[?25h[?25l[30d[2;29r[2;1HM[1;32r[2;1H[36m# ignore all logs[3d[39m(B[m*.logchangeps1: False[6G[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- [94mhttp://some.custom/channel[3d[39m(B[m[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- file:///some/local/directory[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- defaults[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- admin[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;1Hdefault_channels:[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- [94mhttp://some.custom/channel[3d[39m(B[m[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- file:///some/local/directory[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- [94mhttps://my-mirror.com/pkgs/main[3d[39m(B[m[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- [94mhttps://my-mirror.com/pkgs/r[3d[39m(B[m[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- [94mhttps://my-mirror.com/pkgs/msys2[3d[39m(B[m[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;1Henvs_dirs:[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- ~/my-envs[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;3H- /opt/anaconda/envs[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;1HCONDA_ENVS_PATH=~/my-envs:/opt/anaconda/envs[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;1Hrestore_free_channel: true[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[3;1H[?12l[?25h[?25l[3;30r[30;1H
[1;32r[29;1HSSL_NO_VERIFY=1 conda skeleton pypi a_package[3d[?12l[?25h[?25l[3;30r[30;1H
[1;32r[3;1H[?12l[?25h[?25l[3;30r[30;1H
[1;32r[3;1H[?12l[?25h[?25l[3;30r[30;1H
[1;32r[2;18H[36mreport_errors: true[2;18H[39m(B[m[?12l[?25h[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[C[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25hreport_errors: true[K[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h true[K[?25l[?12l[?25htrue[K[?25l[?12l[?25hrue[K[?25l[?12l[?25hue[K[?25l[?12l[?25he[K[?25l[?12l[?25h[K[?25l[2;30r[30;1H
[1;32r[2;1H[?12l[?25h[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25hFalse[K[?25l[?12l[?25halse[K[?25l[?12l[?25hlse[K[?25l[?12l[?25hse[K[?25l[?12l[?25he[K[?25l[?12l[?25h[K[?25l[2;30r[30;1H
[1;32r[2;1H[?12l[?25h[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h True[K[?25l[?12l[?25hTrue[K[?25l[?12l[?25hrue[K[?25l[?12l[?25hue[K[?25l[?12l[?25he[K[?25l[?12l[?25h[K[?25l[2;30r[30;1H
[1;32r[2;1H[?12l[?25h[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h True[K[?25l[?12l[?25hTrue[K[?25l[?12l[?25hrue[K[?25l[?12l[?25hue[K[?25l[?12l[?25he[K[?25l[?12l[?25h[K[?25l[2;30r[30;1H
[1;32r[2;1H[?12l[?25h[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25hnels:[K[?25l[?12l[?25hels:[K[?25l[?12l[?25hls:[K[?25l[?12l[?25hs:[K[?25l[?12l[?25h:[K[?25l[?12l[?25h[K[?25l[2;30r[30;1H
[1;32r[2;1H[?12l[?25h[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25https://my-mirror.com/conda-forge[K[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25hforge[K[?25l[?12l[?25horge[K[?25l[?12l[?25hrge[K[?25l[?12l[?25hge[K[?25l[?12l[?25he[K[?25l[?12l[?25h[K[?25l[2;30r[30;1H
[1;32r[2;1H[?12l[?25h[?25l[?12l[?25h[3d[?25l[?12l[?25h[4d[?25l[?12l[?25h[5d[?25l[?12l[?25h[6d[?25l[?12l[?25h[7d[?25l[?12l[?25h[8d[?25l[?12l[?25h[9d[?25l[?12l[?25h[10d[?25l[?12l[?25h[11d[?25l[?12l[?25h[12d[?25l[?12l[?25h[13d[?25l[?12l[?25h[14d[?25l[?12l[?25h[15d[?25l[?12l[?25h[16d[?25l[?12l[?25h[17d[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h[1P[?25l[?12l[?25h/envs[K[?25l[?12l[?25henvs[K[?25l[?12l[?25hnvs[K[?25l[?12l[?25hvs[K[?25l[?12l[?25hs[K[?25l[?12l[?25h[K[?25l[31;15H(B[0;7mM-D(B[m DOS Format(B[0;7mM-A(B[m Append    (B[0;7mM-B(B[m Backup File[32;2H(B[0;7mC(B[m Cancel     (B[0;7mM-M(B[m Mac Format(B[0;7mM-P(B[m Prepend   (B[0;7m^T(B[m Browse[30d(B[0;7mFile Name to Write: .condarc                               [30;29H(B[m[?12l[?25h[?25l[22G[1K (B[0;7m[ Writing... ](B[m[K[1;38H(B[0;7m [58G(B[m[30;21H(B[0;7m[ Wrote 19 lines ](B[m[31;15H(B[0;7m^O(B[m Write Out  (B[0;7m^W(B[m Where Is   (B[0;7m^K(B[m Cut[K[32;2H(B[0;7mX(B[m Exit       (B[0;7m^R(B[m Read File  (B[0;7m^\(B[m Replace    (B[0;7m^U(B[m Paste[K[?12l[?25h[17d[?25l[30d[J[32d[?12l[?25h[32;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ nano .condarcarc[9Pcd ..onda env export >environment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [Cd ..[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cnano .condaarc[1Prc[Kcd mle-training
[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ cd mle-training[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano .condarc[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[Carc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7Pcd ..
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Conda env export >environment.yml
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git rm .cond aar[K[Krc
[?2004lfatal: pathspec '.condarc' did not match any files
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ cd ..
[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ cd ..git rm .condarc
[?2004lfatal: not a git repository (or any of the parent directories): .git
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ ls
[?2004lEPA_SmartLocationDatabase_V3_Jan_2021_Final.csv
dhikshita_assignment1.2
dhikshita_git
dhikshita_miniconda
environment.yaml
[0m[01;34mgit[0m
[01;34mgit_proj[0m
[01;34mminiconda3[0m
[01;34mmle-training[0m
[01;34mmy-project[0m
outputfile.txt
spec-file.txt
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ r[Klsgit rm .condarc[10Pcd ..git rm .condarcconda env export >environment.yml[1P.yml[1P.yml[C[C[1P.yml[C[1P.yml[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.y[1Pml[A(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.ym[1Pl[A(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.yml[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.yml [K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ conda env export >env.yml [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit rm .condarc[10Pcd ..git rm .condarcconda env export >environment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~[01;32mdhikshita@TIGER04454[00m:[01;34m~[00m$ [C[10Pd mle-training
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ cd mle-training[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [Conda env export >env.yml
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls
[?2004lREADME.md  env.yml  environment.yml  nonstandardcode.py
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda rm env .yml
[?2004lIgnoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
Ignoring configuration file (/home/dhikshita/.condarc) due to error:
Unable to load configuration file.
  path: /home/dhikshita/.condarc
  reason: invalid yaml at line 19, column 0
usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...
conda: error: argument COMMAND: invalid choice: 'rm' (choose from 'activate', 'deactivate', 'clean', 'compare', 'config', 'create', 'env', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'content-trust', 'doctor', 'repoquery')
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls
[?2004lREADME.md  env.yml  environment.yml  nonstandardcode.py
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls
[?2004lREADME.md  environment.yml  nonstandardcode.py
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls[Kgit add envi ronment.yml
[?2004l[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git add environment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cconda rm env.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cconda env export >env.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [Cd mle-training[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [Conda env export >env.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit rm .condarc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7Pcd ..
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit rm .condarc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7Pcd ..
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit rm .condarc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda env export >environment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [Cd mle-training[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano .condarc[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[Carc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7Pcd ..
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Conda env export >environment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[Cinstall[13P python[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[Cactivate mle_dev[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git push -f origin enh/1/issue1.2[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Ccommit -m "New Branch Commit" 
[?2004l[enh/1/issue1.2 04785b0] New Branch Commit
 1 file changed, 28 insertions(+)
 create mode 100644 environment.yml
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git commit -m "New Branch Commit" [A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[Cadd envir[11Ponment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cconda rm env.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cconda env export >env.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [Cd mle-training[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [Conda env export >env.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ ls[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit rm .condarc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7Pcd ..
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cgit rm .condarc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ conda env export >environment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [Cd mle-training[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ nano .condarc[K[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C[Carc[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [7Pcd ..
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Conda env export >environment.yml[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[Cinstall[13P python[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[Cactivate mle_dev[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ git push -f origin enh/1/issue1.2
[?2004lEnumerating objects: 4, done.
Counting objects:  25% (1/4)Counting objects:  50% (2/4)Counting objects:  75% (3/4)Counting objects: 100% (4/4)Counting objects: 100% (4/4), done.
Delta compression using up to 12 threads
Compressing objects:  33% (1/3)Compressing objects:  66% (2/3)Compressing objects: 100% (3/3)Compressing objects: 100% (3/3), done.
Writing objects:  33% (1/3)Writing objects:  66% (2/3)Writing objects: 100% (3/3)Writing objects: 100% (3/3), 770 bytes | 385.00 KiB/s, done.
Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
To github.com:Dhikshita-macherla/mle-training.git
   c220def..04785b0  enh/1/issue1.2 -> enh/1/issue1.2
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ python nosta ndardcode.py
[?2004lpython: can't open file '/home/dhikshita/mle-training/nostandardcode.py': [Errno 2] No such file or directory
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ python nostandardcode.py[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cnstandardcode.py[A(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ [C[C[C[C[C[C[C[C[C[C

[?2004lTraceback (most recent call last):
  File "/home/dhikshita/mle-training/nonstandardcode.py", line 1, in <module>
    import numpy as np
ModuleNotFoundError: No module named 'numpy'
[?2004h(mle_dev) ]0;dhikshita@TIGER04454: ~/mle-training[01;32mdhikshita@TIGER04454[00m:[01;34m~/mle-training[00m$ exit
[?2004lexit

Script done on 2024-03-13 17:51:07+05:30 [COMMAND_EXIT_CODE="1"]
